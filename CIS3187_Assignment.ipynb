{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIS3187_Assignment",
      "provenance": [],
      "collapsed_sections": [
        "R6wTEJZ1Fb4n",
        "6EUZKI9BE6Jt",
        "9QNW69nYEKsB",
        "bEtD9oeBHPJ0",
        "VyQA14YtG32G",
        "V7Z2w60LehO4",
        "gXG7Fs-s1iC2",
        "GwREMbx6Xcqv",
        "r6tHb_km7pWD",
        "RL8KlR0XzDoo"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKnHG-P2JATz",
        "colab_type": "text"
      },
      "source": [
        "# Implementing a Multi-layer Perceptron (MLP)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQE8qP4wj59U",
        "colab_type": "text"
      },
      "source": [
        "# Statement of Completion\n",
        "All deliverables and requirements of this assignment have been fulfiled, as per the respective coursework specification document.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic8Fy7Z4I3bs",
        "colab_type": "text"
      },
      "source": [
        "# Design Decisions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TDZRmjzh2KY",
        "colab_type": "text"
      },
      "source": [
        "Given the nature of the task, it was decided to opt to use Python as the language for implementing the MLP. Python is an extremely popular programming language in general, moreso for projects that make use of, or require, Data Science and Machine Learning. Its popularity in such a field draws credit from ML libraries such as Scikit-learn and Keras, as well as other libraries such as Numpy, which was used extensively throughout this assignment. \n",
        "\n",
        "When designing the flow of this project, it was made sure that configurability was given high importance, such that the different parameters of the MLP could be tweaked and adjusted very easily. As a reuslt, a parameter-centric design was adopted. As can be seen in the code section, the MLP class has a dependency class *parameters*, which does as the name implies. After experimenting with multiple configurations, the best approach in this case was found to be using a single hidden layer containing four neurons. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZuKRcCYIohW",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRU9fhLHawWJ",
        "colab_type": "text"
      },
      "source": [
        "## Project Imports\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCf0VH3RPV9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtxRNPSguh_-",
        "colab_type": "text"
      },
      "source": [
        "## MLP Parameters\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f20hU83uoEQ",
        "colab_type": "text"
      },
      "source": [
        "The Neural Network contains the following parameters:\n",
        "*   **Number of input neurons**: 5\n",
        "*   **Number of output neurons**: 3\n",
        "*   **Number of hidden layers**: 1\n",
        "*   **Number of hidden neurons**: 4\n",
        "*   **Error threshold**: 0.2\n",
        "*   **Learning rate**: 0.2\n",
        "*   **Maximum number of epochs**: 999\n",
        "*   **Transformation function**: Sigmoid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-nH_HyUl_vq",
        "colab_type": "text"
      },
      "source": [
        "#### Declare parameters in a designated class, to be referenced by the implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cgz9DfPwveo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class parameters:\n",
        "  NUM_IN_NEURONS = 5\n",
        "  NUM_OUT_NEURONS = 3\n",
        "  NUM_HIDDEN_LAYERS = 1\n",
        "  NUM_HIDDEN_NEURONS = 4\n",
        "  ERROR_THRESHOLD = 0.2\n",
        "  LEARNING_RATE = 0.2\n",
        "  MAX_EPOCHS = 999"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYW0GXfD0zeo",
        "colab_type": "text"
      },
      "source": [
        "#### Sigmoid Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTx8XyNOytcL",
        "colab_type": "text"
      },
      "source": [
        "The method will be called *transform()* so as to remain generic and \"hotswappable\" with other transformation functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGt1VupQy37w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform(x):\n",
        "  #sigmoid\n",
        "  return 1 / (1 + np.exp(-x))  \n",
        "\n",
        "#add to MLP parameters\n",
        "parameters.transform = transform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JuBbdzpiaFQ",
        "colab_type": "text"
      },
      "source": [
        "## Dataset Used\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HRQHkktq9c7",
        "colab_type": "text"
      },
      "source": [
        "The MLP reads a 5-bit boolean function and maps it to a 3-bit result. As such, the dataset is made up of 32 rows of a binary *input* mapped to another binary *output* via the function Â¬ABC. 26 rows, selected randomly, are to be used for training and the remaining 6 to test the Perceptron.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nYbnwl8pFmR",
        "colab_type": "text"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMvfwpNuuRYg",
        "colab_type": "text"
      },
      "source": [
        "#### Begin by importing data from a .csv file and store in a pandas DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OzKGOO4RDZV",
        "colab_type": "code",
        "outputId": "f69ca773-af0e-47f5-e8c1-69b37bab266c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_url = \"https://raw.githubusercontent.com/DeltSystem32/CIS3187-Assignment/master/full_dataset.csv?token=AIW66N4UA46SZD3JMZIWU7C6ERXXE\"\n",
        "df = pd.read_csv(data_url, converters={'input': lambda x: str(x), 'output': lambda x: str(x)})\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Num</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>00000</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>00001</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>00010</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>00011</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>00100</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>00101</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>00110</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>00111</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>01000</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>01001</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>01010</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>01011</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>01100</td>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>01101</td>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>01110</td>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>01111</td>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>10000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>10001</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>10010</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>10011</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>10100</td>\n",
              "      <td>001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>10101</td>\n",
              "      <td>001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>10110</td>\n",
              "      <td>001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>10111</td>\n",
              "      <td>001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>11000</td>\n",
              "      <td>010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>11001</td>\n",
              "      <td>010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>11010</td>\n",
              "      <td>010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "      <td>11011</td>\n",
              "      <td>010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>29</td>\n",
              "      <td>11100</td>\n",
              "      <td>011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30</td>\n",
              "      <td>11101</td>\n",
              "      <td>011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>31</td>\n",
              "      <td>11110</td>\n",
              "      <td>011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>32</td>\n",
              "      <td>11111</td>\n",
              "      <td>011</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Num  input output\n",
              "0     1  00000    100\n",
              "1     2  00001    100\n",
              "2     3  00010    100\n",
              "3     4  00011    100\n",
              "4     5  00100    101\n",
              "5     6  00101    101\n",
              "6     7  00110    101\n",
              "7     8  00111    101\n",
              "8     9  01000    110\n",
              "9    10  01001    110\n",
              "10   11  01010    110\n",
              "11   12  01011    110\n",
              "12   13  01100    111\n",
              "13   14  01101    111\n",
              "14   15  01110    111\n",
              "15   16  01111    111\n",
              "16   17  10000    000\n",
              "17   18  10001    000\n",
              "18   19  10010    000\n",
              "19   20  10011    000\n",
              "20   21  10100    001\n",
              "21   22  10101    001\n",
              "22   23  10110    001\n",
              "23   24  10111    001\n",
              "24   25  11000    010\n",
              "25   26  11001    010\n",
              "26   27  11010    010\n",
              "27   28  11011    010\n",
              "28   29  11100    011\n",
              "29   30  11101    011\n",
              "30   31  11110    011\n",
              "31   32  11111    011"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1030
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8JUvI52pPaX",
        "colab_type": "text"
      },
      "source": [
        "#### Shuffle rows of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uR3uX9ISoVU",
        "colab_type": "code",
        "outputId": "bf36ca97-2c03-46ed-f82e-2261cc875888",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Num</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>01000</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>01101</td>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29</td>\n",
              "      <td>11100</td>\n",
              "      <td>011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24</td>\n",
              "      <td>10111</td>\n",
              "      <td>001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25</td>\n",
              "      <td>11000</td>\n",
              "      <td>010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Num  input output\n",
              "0    9  01000    110\n",
              "1   14  01101    111\n",
              "2   29  11100    011\n",
              "3   24  10111    001\n",
              "4   25  11000    010"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1031
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzC24pkPTWWU",
        "colab_type": "text"
      },
      "source": [
        "#### Separate into training and testing datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu8Oj0tUrQr9",
        "colab_type": "text"
      },
      "source": [
        "##### Training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8o8kWlzdjaT",
        "colab_type": "code",
        "outputId": "2fc8f32c-0fe4-486e-f024-0cbf42ea21fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_df = df[:26]\n",
        "training_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Num</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>01000</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>01101</td>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29</td>\n",
              "      <td>11100</td>\n",
              "      <td>011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24</td>\n",
              "      <td>10111</td>\n",
              "      <td>001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25</td>\n",
              "      <td>11000</td>\n",
              "      <td>010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Num  input output\n",
              "0    9  01000    110\n",
              "1   14  01101    111\n",
              "2   29  11100    011\n",
              "3   24  10111    001\n",
              "4   25  11000    010"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1032
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGnvq_MSqVgB",
        "colab_type": "text"
      },
      "source": [
        "##### Testing set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17jSKbZGdTrn",
        "colab_type": "code",
        "outputId": "b5342f8b-167b-4e8f-c581-9c43513e354b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "testing_df = df[26:]\n",
        "testing_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Num</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>4</td>\n",
              "      <td>00011</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>17</td>\n",
              "      <td>10000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>27</td>\n",
              "      <td>11010</td>\n",
              "      <td>010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>5</td>\n",
              "      <td>00100</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2</td>\n",
              "      <td>00001</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Num  input output\n",
              "26    4  00011    100\n",
              "27   17  10000    000\n",
              "28   27  11010    010\n",
              "29    5  00100    101\n",
              "30    2  00001    100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1033
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7JpW4CyqpTa",
        "colab_type": "text"
      },
      "source": [
        "#### Size of  datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IfZRHKuqBOW",
        "colab_type": "code",
        "outputId": "23a5f13b-a1ab-4a0c-ac24-7f5d59556738",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Size of training set: \" + str(len(training_df)))\n",
        "print(\"Size of testing set: \"+ str(len(testing_df)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of training set: 26\n",
            "Size of testing set: 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvTzzHBv0oNE",
        "colab_type": "text"
      },
      "source": [
        "## Code Implementation\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6wTEJZ1Fb4n",
        "colab_type": "text"
      },
      "source": [
        "##### Begin with the MLP's initialisation function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4nuccLrD4Lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP:\n",
        "  wH = None #hidden layer weights\n",
        "  wO = None #output layer weights\n",
        "  epochs_list = None\n",
        "    \n",
        "  def __init__(self):\n",
        "    global wH, wO\n",
        "    \n",
        "    wH = self.generate_weights(parameters.NUM_IN_NEURONS,parameters.NUM_HIDDEN_NEURONS)\n",
        "    wO = self.generate_weights(parameters.NUM_HIDDEN_NEURONS,parameters.NUM_OUT_NEURONS)\n",
        "\n",
        "    print(\"Weights randomly generated.\")\n",
        "    print(\"Hidden weights:\\n\", wH)\n",
        "    print(\"Output weights:\\n\", wO)      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EUZKI9BE6Jt",
        "colab_type": "text"
      },
      "source": [
        "##### To initialise the weights, we will need to do so randomly from -1 to 1. For this, a function is required to create a matrix of weights of any given size:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s63gI84MECim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_weights(self, columns, rows):\n",
        "  return np.random.uniform(low=-1,high=1, size=(columns,rows))\n",
        "\n",
        "#add to MLP\n",
        "MLP.generate_weights = generate_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXbEHQGIu48N",
        "colab_type": "text"
      },
      "source": [
        "##### Define the training function that accepts a dataframe and carries out forward and backward propagation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13749n3FvDm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(self, input_df):\n",
        "    global wH, wO, epochs_list\n",
        "    epochs_list = []\n",
        "\n",
        "    epoch = 1\n",
        "    print(\"------------------------------------------\")\n",
        "    while epoch <= parameters.MAX_EPOCHS:\n",
        "      num_bad_facts = 0\n",
        "      print(\"Epoch \", epoch)\n",
        "      \n",
        "      for index, fact in input_df.iterrows():\n",
        "        # obtain output and output columns from dataframe\n",
        "        input = np.array(list(fact[\"input\"]),dtype=np.float64)\n",
        "        target_output = np.array(list(fact[\"output\"]),dtype=np.float64) \n",
        "\n",
        "        # feedforward\n",
        "        result = self.feedforward(input, target_output, wH, wO)\n",
        "        output, outH = result[0], result[1]\n",
        "\n",
        "        # calculate error\n",
        "        error = self.get_error_count(target_output, output)\n",
        "\n",
        "        # check error - if less than threshold, perform backpropagation\n",
        "        good_fact = self.check_fact(error)\n",
        "        if not good_fact:\n",
        "          num_bad_facts += 1\n",
        "          print(\"False\")\n",
        "          result = self.error_backpropagation(parameters.LEARNING_RATE, output, outH, target_output, input, wH, wO)\n",
        "        else:\n",
        "          print(\"True\")\n",
        "\n",
        "      epochs_list.append([epoch, ((num_bad_facts / len(input_df)) * 100)])\n",
        "      epoch += 1\n",
        "      print(\"------------------------------------------\")\n",
        "\n",
        "      if num_bad_facts == 0:\n",
        "        print(\"Converged!!!!!!!!!!!!\")\n",
        "        break\n",
        "\n",
        "MLP.train = train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utvXRbUXAf4E",
        "colab_type": "text"
      },
      "source": [
        "##### Define the test() function that will be used to classify data from a given dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBrb_3O2Akoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(self, input_df):\n",
        "    good_facts = 0\n",
        "    for index, fact in input_df.iterrows():\n",
        "      # get input and output from dataframe\n",
        "      input = np.array(list(fact[\"input\"]),dtype=np.float64)\n",
        "      target_output = np.array(list(fact[\"output\"]),dtype=np.float64)\n",
        "\n",
        "      # feedforward\n",
        "      result = self.feedforward(input, target_output, wH, wO) \n",
        "      output = result[0]\n",
        "      \n",
        "      # calculate error\n",
        "      error = self.get_error_count(target_output, output)\n",
        "      print(input, \"---------->\", output)\n",
        "\n",
        "      # check error\n",
        "      is_good_fact = self.check_fact(error)\n",
        "      if is_good_fact:\n",
        "        good_facts += 1\n",
        "\n",
        "      print(bool(is_good_fact), \"! (Target: \",target_output,\")\")\n",
        "\n",
        "    print(\"\\nAccuracy: \", self.calculate_accuracy(len(input_df), good_facts), \"%\")\n",
        "\n",
        "MLP.test = test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz8f0MXABEHL",
        "colab_type": "text"
      },
      "source": [
        "##### Function for obtaining the accuracy rating of good facts over total facts:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "213a8Q_9BDT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_accuracy(self, input_size, good_facts):\n",
        "  return (good_facts / input_size) * 100\n",
        "\n",
        "MLP.calculate_accuracy = calculate_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QNW69nYEKsB",
        "colab_type": "text"
      },
      "source": [
        "### Feed-forward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEtD9oeBHPJ0",
        "colab_type": "text"
      },
      "source": [
        "##### Function for applying the transformation function to all cells of a given array:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxwIzP7tFkzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_array(self, net):\n",
        "  return [parameters.transform(j) for j in net]\n",
        "\n",
        "# add to MLP\n",
        "MLP.transform_array = transform_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyQA14YtG32G",
        "colab_type": "text"
      },
      "source": [
        "##### Loop through hidden layer and output layer, transforming input into MLP output. Matrix multiplication is performed using numpy's dot function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A-L6yku0p9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feedforward(self, input, target, wH, wO):\n",
        "  # Hidden layer\n",
        "  netH = np.dot(input, wH).astype(np.float64) \n",
        "  outH = parameters.transform(netH) \n",
        "\n",
        "  # Output layer\n",
        "  netO = np.dot(outH, wO).astype(np.float64) \n",
        "  outO = parameters.transform(netO) \n",
        "\n",
        "  return outO, outH\n",
        "\n",
        "MLP.feedforward = feedforward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7Z2w60LehO4",
        "colab_type": "text"
      },
      "source": [
        "### Fact Checking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drrJQ5JQxOiI",
        "colab_type": "text"
      },
      "source": [
        "##### For each output of the MLP, compare with the expected output and produce the error difference: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3JifR0EbJYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_error_count(self, target, outO):\n",
        "  errorCount = np.array(len(outO),dtype=np.float64)\n",
        "  errorCount = np.absolute(target - outO)\n",
        "  return errorCount\n",
        "\n",
        "MLP.get_error_count = get_error_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVT92Svs1Rzn",
        "colab_type": "text"
      },
      "source": [
        "##### Given an array of errors, compare to error threshold and determine whether fact is good or bad:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xne2xlUbeslB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_fact(self, errorCount):\n",
        "  threshold = parameters.ERROR_THRESHOLD\n",
        "  for error in errorCount: \n",
        "    if error > threshold: \n",
        "      return False \n",
        "  return True\n",
        "\n",
        "MLP.check_fact = check_fact"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXG7Fs-s1iC2",
        "colab_type": "text"
      },
      "source": [
        "### Error Backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U92HKjg8XJT_",
        "colab_type": "text"
      },
      "source": [
        "##### Revise the weights of the MLP, beginning from the output layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q362lwt1hh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def error_backpropagation(self, learning_rate, outO, outH, target, input, wH, wO):\n",
        "  #output layer\n",
        "  delta_out = self.calculate_out_delta(outO, target)\n",
        "  wO = self.calculate_out_weights(learning_rate, delta_out, outH, wO)\n",
        "\n",
        "  #hidden layer \n",
        "  delta_hidden = self.calculate_delta_hidden(delta_out, outH, wO)\n",
        "  wH = self.calculate_hidden_weights(learning_rate, delta_hidden, input, wH)\n",
        "\n",
        "  return wO, wH\n",
        "\n",
        "MLP.error_backpropagation = error_backpropagation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwREMbx6Xcqv",
        "colab_type": "text"
      },
      "source": [
        "#### Output layer weights:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckQMif3H3C02",
        "colab_type": "text"
      },
      "source": [
        "##### Determine the output delta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMCiOsJM90-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_out_delta(self, outO, target): \n",
        "  deltas = np.empty(len(outO), dtype=np.float64)\n",
        "  for i in range(len(outO)):\n",
        "      deltas[i] = outO[i] * (1 - outO[i]) * (target[i] - outO[i])\n",
        "\n",
        "  return deltas\n",
        "\n",
        "MLP.calculate_out_delta = calculate_out_delta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUOKpSBx38Aj",
        "colab_type": "text"
      },
      "source": [
        "##### Determine the new output weights: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLoar1p-33Y2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_out_weights(self, learning_rate, delta_out, outH, wO): \n",
        "  for i in range(len(outH)):\n",
        "      for j in range(len(delta_out)):\n",
        "          wO[i][j] += learning_rate * delta_out[j] * outH[i]\n",
        "\n",
        "  return wO\n",
        "\n",
        "MLP.calculate_out_weights = calculate_out_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6tHb_km7pWD",
        "colab_type": "text"
      },
      "source": [
        "#### Hidden layer weights:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3YQPj9xXkC4",
        "colab_type": "text"
      },
      "source": [
        "Do the same for the weights of the hidden layer. This follows a more complex process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxBiGzdX7uHu",
        "colab_type": "text"
      },
      "source": [
        "##### Determine the hidden layer delta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZyu_5WGOHuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_delta_hidden(self, deltaO, outH, wO): \n",
        "  deltas = np.empty(len(outH), dtype=np.float64)\n",
        "  for i in range(len(outH)):\n",
        "    deltas[i] = (outH[i] * (1 - outH[i]) * (self.calculate_delta_summation(deltaO, i, wO)))\n",
        "    \n",
        "  return deltas\n",
        "\n",
        "MLP.calculate_delta_hidden = calculate_delta_hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu_676FI82Zz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def calculate_delta_summation(self, output_delta, index, wO): \n",
        "  sum = 0\n",
        "  for i in range(len(output_delta)):\n",
        "    sum += (output_delta[i] * wO[index, i])\n",
        "\n",
        "  return sum\n",
        "\n",
        "MLP.calculate_delta_summation = calculate_delta_summation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB1LENTq9qrH",
        "colab_type": "text"
      },
      "source": [
        "##### Determine the hidden layer weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ghpCkeC9sMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_hidden_weights(self, learning_rate, delta_hidden, input, wH): \n",
        "  for i in range(len(input)):\n",
        "      for j in range(len(delta_hidden)):\n",
        "          wH[i][j] += learning_rate * delta_hidden[j] * input[i]\n",
        "          \n",
        "  return wH\n",
        "\n",
        "MLP.calculate_hidden_weights = calculate_hidden_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL8KlR0XzDoo",
        "colab_type": "text"
      },
      "source": [
        "### Graph Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ9Vrla5zHhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot(self):\n",
        "  epochs = np.array(epochs_list)\n",
        "\n",
        "  for e in epochs_list:\n",
        "    np.append(epochs, e)\n",
        "  \n",
        "  plt.plot(epochs[:,0], epochs[:,1])\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('% of Bad Facts')\n",
        "\n",
        "  plt.title(\"Bad Facts - Epochs Graph\")\n",
        "  plt.show()\n",
        "\n",
        "MLP.plot = plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8FHWi-vZYWU",
        "colab_type": "text"
      },
      "source": [
        "### Runner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O39jR5lgCKdD",
        "colab_type": "text"
      },
      "source": [
        "Initialise the Multi-layer Perceptron."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e1JtTJBJr5P",
        "colab_type": "code",
        "outputId": "9acde7ac-cef9-4adc-ebbd-036aa6582f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "mlp = MLP()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights randomly generated.\n",
            "Hidden weights:\n",
            " [[ 0.04717368 -0.53433378  0.31735899  0.42576789]\n",
            " [ 0.57257698  0.35640975 -0.04705558 -0.33912611]\n",
            " [ 0.90521653 -0.79030091  0.21940968  0.18516887]\n",
            " [-0.59227812  0.53354125  0.8453087   0.5689175 ]\n",
            " [ 0.41461757 -0.02557916 -0.30508005  0.2162029 ]]\n",
            "Output weights:\n",
            " [[ 0.99103934  0.54561191 -0.00874823]\n",
            " [ 0.7857513   0.52415151  0.95274097]\n",
            " [ 0.50259516 -0.2583689  -0.45680376]\n",
            " [ 0.14848714 -0.46852693  0.00683001]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoZuiQltCNXN",
        "colab_type": "text"
      },
      "source": [
        "Train the NN with the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMx4VCQ0JOfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp.train(training_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgE0gKwUCzeb",
        "colab_type": "text"
      },
      "source": [
        "Test the perceptron using the testing dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBv4Z3bVhMl_",
        "colab_type": "text"
      },
      "source": [
        "## Facts over Epochs Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOrf4hf9CSyr",
        "colab_type": "text"
      },
      "source": [
        "As can be seen from the below graph, the result is non-monotonic, and clearly illustrates the MLP's learning progress across all epochs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPgerHRtQ7o_",
        "colab_type": "code",
        "outputId": "7bfcd480-b28d-4fb3-9b7d-6f2154d466b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "mlp.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1ceRLc0oWMc",
        "colab_type": "text"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4h-7KxtlOR-",
        "colab_type": "code",
        "outputId": "0f4ab2a9-6838-4d6a-8c24-cdb0e8d68dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "mlp.test(testing_df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 1. 1.] ----------> [0.92851383 0.09595286 0.14115295]\n",
            "True ! (Target:  [1. 0. 0.] )\n",
            "[1. 0. 0. 0. 0.] ----------> [0.14452199 0.09745992 0.15529479]\n",
            "True ! (Target:  [0. 0. 0.] )\n",
            "[1. 1. 0. 1. 0.] ----------> [0.18865015 0.87859423 0.12530087]\n",
            "True ! (Target:  [0. 1. 0.] )\n",
            "[0. 0. 1. 0. 0.] ----------> [0.72443813 0.18081394 0.88784415]\n",
            "False ! (Target:  [1. 0. 1.] )\n",
            "[0. 0. 0. 0. 1.] ----------> [0.87441798 0.14913198 0.17489075]\n",
            "True ! (Target:  [1. 0. 0.] )\n",
            "[0. 1. 0. 1. 0.] ----------> [0.91935698 0.87818715 0.17011708]\n",
            "True ! (Target:  [1. 1. 0.] )\n",
            "\n",
            "Accuracy:  83.33333333333334 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOyPc5sDrKKJ",
        "colab_type": "text"
      },
      "source": [
        "As can be seen from the above code snippet, the test produced a classification accuracy of 83.3%. The testing dataset (which contains six values) was used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_wQB_lomTTS",
        "colab_type": "text"
      },
      "source": [
        "## Issues Encountered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHwlBkrQmaax",
        "colab_type": "text"
      },
      "source": [
        "The bulk of issues stemmed from the alignment of indices of the several Numpy arrays and matrices which were used throughout the project, which were greatly impacting the MLP's performance. There were also some issues involving improper indentation of code instructions that, in Python, function differently if misaligned. Another issue which took a substantial amount of time arose from the error-checking component, in which multiplication was returning skewed results. This was determined to have been caused by losses in precision due to the conversion of certain array elements. "
      ]
    }
  ]
}